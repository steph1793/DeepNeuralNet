{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepNeuralNet_FromScratch.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/steph1793/DeepNeuralNet/blob/master/DeepNeuralNet_FromScratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "rLZYpEXGOGFk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Deep Neural Network From Scratch"
      ]
    },
    {
      "metadata": {
        "id": "I6HJWJQaOOQi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "%%html\n",
        "<img src=\"https://www.podcastscience.fm/wp-content/uploads/2015/09/Machine-Learning.jpg\" width=\"600\" >"
      ]
    },
    {
      "metadata": {
        "id": "zsgbmF2IobLK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import random\n",
        "\n",
        "\n",
        "import gzip\n",
        "import signal\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "from tensorflow.keras.datasets import mnist # for mnist dataset\n",
        "from random import randint\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kskg-cWdCehS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## MNIST dataset importation from tensorflow keras"
      ]
    },
    {
      "metadata": {
        "id": "VOy4muLTo87K",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "mnist = mnist\n",
        "(train_images, train_labels),(test_images, test_labels) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9Ur_0-ovCn4U",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### We normalize and reshape the data"
      ]
    },
    {
      "metadata": {
        "id": "cJ0aQCGVq2X5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_images, test_images = train_images/255.0, test_images/255.0\n",
        "train_images = np.reshape(train_images, (-1,784))\n",
        "test_images = np.reshape(test_images, (-1, 784))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wCivVTYQ2-KR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def batches( x,y, batch_size):\n",
        "  gather = list(zip(x,y))\n",
        "  random.shuffle(gather)\n",
        "  return [gather[i:i+batch_size] for i in range(0,len(gather),batch_size) ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-rp8YyN2Cv6Y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Activations functions and their derivatives"
      ]
    },
    {
      "metadata": {
        "id": "C2aAL1r82pIi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def sigmoid(z):\n",
        "  return 1/(1+np.exp(-z))\n",
        "\n",
        "def sigmoid_derivative(z):\n",
        "  return sigmoid(z)*(1-sigmoid(z))\n",
        "\n",
        "def softmax(z):\n",
        "  res = [math.exp(i) for i in z]\n",
        "  sum = np.sum(res)\n",
        "  return res/sum\n",
        "\n",
        "def softmax_derivative(z):\n",
        "  return z # todo\n",
        "\n",
        "\n",
        "def relu(z):\n",
        "  return np.maximum(0,z)\n",
        "\n",
        "def relu_derivative(z):\n",
        "  return [0 if i<= 0 else 1 for i in z]\n",
        "\n",
        "def leaky_relu(z):\n",
        "  return [0.01*x if x<=0 else x for x in z ]\n",
        "\n",
        "def leaky_relu_derivative(z):\n",
        "  return [0.01 if i<= 0 else 1 for i in z]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iA1Bzeh3y3dh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sigmoid_pack = {'function' : sigmoid, 'derivative' :sigmoid_derivative }\n",
        "softmax_pack = {'function' :softmax , 'derivative' :softmax_derivative }\n",
        "relu_pack = {'function' :relu , 'derivative' :relu_derivative}\n",
        "leaky_relu_pack =  {'function' : leaky_relu , 'derivative' : leaky_relu_derivative}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EIY0Vdp6C6aG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Regularization functions"
      ]
    },
    {
      "metadata": {
        "id": "0Sg66hws2vrW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def L2(eta, lambd, training_size, weights):\n",
        "  return (1 - eta*lambd /training_size)*weights\n",
        "\n",
        "def L1(eta, lambd, training_size, weights):\n",
        "  return (weights - eta*lambd/training_size*np.sign(weights))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "E7PGTFzcC_GY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Cost functions and final layer deltas"
      ]
    },
    {
      "metadata": {
        "id": "fFmTGBiy4Osx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def cross_entropy(a,y):\n",
        "  return np.array(y) * np.array(math.log(a))\n",
        "\n",
        "def cross_entropy_softmax_final_delta(z, a,y):\n",
        "  return a-y\n",
        "\n",
        "\n",
        "def MSE(a,y):\n",
        "  return np.linalg.norm(a-y, 2)\n",
        "\n",
        "def MSE_sigmoid_final_delta(z,a,y):\n",
        "  np.array(sigmoid_derivative(z)) * np.array(a - y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DnTf2RSYDjdI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "MSE_sigmoid_pack = {'function' : MSE, 'delta' :MSE_sigmoid_final_delta }\n",
        "cross_entropy_softmax_pack = {'function' : cross_entropy, 'delta' : cross_entropy_softmax_final_delta }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "c7xVX3j0DGni",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Simple neural network class"
      ]
    },
    {
      "metadata": {
        "id": "UbINNPWJDOpI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "By default we use sigmoid function as an activation function"
      ]
    },
    {
      "metadata": {
        "id": "-hzk3wcdoeNr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Network:\n",
        "  def __init__(self, sizes, activation = leaky_relu_pack, final_layer_activation=softmax_pack):\n",
        "    self.layer_num = len(sizes)\n",
        "    self.sizes = sizes ## layers sizes\n",
        "    self.default_weights_initializer()\n",
        "\n",
        "\n",
        "    self.activation = activation['function']\n",
        "    self.final_layer_activation = final_layer_activation['function']\n",
        "\n",
        "    self.activation_derivative = activation['derivative']\n",
        "    self.final_layer_activation_derivative = final_layer_activation['derivative']\n",
        "\n",
        "\n",
        "  def default_weights_initializer(self):\n",
        "    sizes = self.sizes\n",
        "    self.weights = [ np.random.randn(sizes[i+1], sizes[i])/np.sqrt(sizes[1]) for i in range(len(sizes)-1)]\n",
        "    self.biases = [np.random.randn(sizes[i]) for i in range(1, len(sizes))]\n",
        "\n",
        "  def large_weights_initializer(self):\n",
        "    sizes = self.sizes\n",
        "    self.weights = [ np.random.randn(sizes[i+1], sizes[i]) for i in range(self.layer_num-1)]\n",
        "    self.biases = [np.random.randn(sizes[i]) for i in range(1, len(sizes))]\n",
        "\n",
        "\n",
        "  def feedforward(self, x):\n",
        "    a = x\n",
        "    z_values = []\n",
        "    a_values = []\n",
        "    a_values.append(x)\n",
        "    liste = list(zip(self.weights, self.biases))\n",
        "    for w, b in liste[:-1] :\n",
        "      z = np.dot(w, a) + b\n",
        "      a = self.activation(z)\n",
        "      a_values.append(a)\n",
        "      z_values.append(z)\n",
        "    w, b = liste[-1]\n",
        "    z =  np.dot(w, a) + b\n",
        "    a = self.final_layer_activation(z)\n",
        "    a_values.append(a)\n",
        "    z_values.append(z)\n",
        "    return z_values, a_values\n",
        "\n",
        "\n",
        "\n",
        "  def test(self, x):\n",
        "    a = x\n",
        "    liste = list(zip(self.weights, self.biases))\n",
        "    for w,b in liste[:-1]:\n",
        "      a = self.activation(np.dot(w,a)+b)\n",
        "    w, b = liste[-1]\n",
        "    a = self.final_layer_activation(np.dot(w,a)+b)\n",
        "    return a\n",
        "\n",
        "\n",
        "\n",
        "  def evaluate(self, test_data, test_labels):\n",
        "    results = [(np.argmax(self.test(x)),y) for (x,y) in list(zip(test_data, test_labels))]\n",
        "    return sum(int(x==y) for (x,y) in results)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RezCXbxGDXZS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Optimizer class"
      ]
    },
    {
      "metadata": {
        "id": "P1EoBV825VFe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Optimizer:\n",
        "  def __init__(self, net):\n",
        "    self.net = net\n",
        "\n",
        "  def backpropagate(self, z_values, out_err):\n",
        "    deltas = []\n",
        "    d = out_err\n",
        "    deltas.append(d)\n",
        "    for l in range(1,self.net.layer_num-1):\n",
        "      d = np.multiply(np.dot(np.transpose(self.net.weights[-l]), d), self.net.activation_derivative(z_values[-l-1])) # we compute the deltas for each layer in the network except the first layer which corresponds to the input\n",
        "      deltas.append(d)\n",
        "    return deltas\n",
        "\n",
        "\n",
        "  def gradient_descent(self, batch_deltas, batch_a_values, eta, batch_size,training_size, regular): # this function computes the gradient descent for one batch of data\n",
        "    for l in range(1, self.net.layer_num):\n",
        "      delta_w = 0\n",
        "      delta_b = 0\n",
        "      for deltas, a_values in list(zip(batch_deltas, batch_a_values)):\n",
        "        d = deltas\n",
        "        a = a_values[::-1]\n",
        "        delta_w = delta_w + np.dot(np.asarray([d[l-1]]).transpose(), np.asarray([a[l]])) \n",
        "        delta_b = delta_b + d[l-1]\n",
        "      if not regular:\n",
        "        self.net.weights[-l] = self.net.weights[-l] -eta/batch_size*delta_w \n",
        "      else:\n",
        "        self.net.weights[-l] = eval(\"{0}\".format(regular[0]))(eta, regular[1], training_size, self.net.weights[-l]) - eta/batch_size*delta_w\n",
        "\n",
        "      self.net.biases[-l] = self.net.biases[-l] - eta/batch_size*delta_b\n",
        "\n",
        "\n",
        "\n",
        "  def Optimize(self, batch, eta, cost, training_size, regular):\n",
        "    batch_deltas = []\n",
        "    batch_a_values = []\n",
        "    for x,y in batch:\n",
        "      z_values, a_values = self.net.feedforward(x)\n",
        "      final_delta = cost['delta'](z_values[-1], a_values[-1],y)\n",
        "      deltas = self.backpropagate(z_values, final_delta)\n",
        "      batch_deltas.append(deltas)\n",
        "      batch_a_values.append(a_values)\n",
        "    self.gradient_descent(batch_deltas, batch_a_values, eta, len(batch), training_size, regular)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p7ZRKucKDhX_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Training function"
      ]
    },
    {
      "metadata": {
        "id": "TI1aJJGN8GmY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train(network, optimizer, training_data, training_labels, batch_size, eta, epochs, test_data=[], test_labels=[], cost=cross_entropy_softmax_pack, regular=[]):\n",
        "  for epoch in range(epochs):\n",
        "    bs = batches(training_data, training_labels, batch_size)\n",
        "    for mini_batch in bs:\n",
        "      optimizer.Optimize(mini_batch, eta,cost, len(training_data), regular)\n",
        "    if test_data.any() and test_labels.any() :\n",
        "                              print(\"Epoch {0} : Accuracy => {1} / {2}\".format(epoch, network.evaluate(test_data, test_labels), len(test_data) ))\n",
        "    else :\n",
        "                              print(\"Epoch {0}\".format(epoch))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t6Dc1LsXDnbq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Labels encoding (to hot vectors) and decoding (to integers)"
      ]
    },
    {
      "metadata": {
        "id": "_wWKrzZGrx3W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "def one_hot(labels):\n",
        "\treturn [ [0 if i != j else 1 for i in range(10)] for j in labels]\n",
        "\n",
        "\n",
        "def decode_output(y):\n",
        "  return np.argmax(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Y0KrHjPJEEQc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## We create network and optimizer objects"
      ]
    },
    {
      "metadata": {
        "id": "2Fja4Xs4rbyS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "net = Network([784,100,10]) ## Here we define the number of layers and their sizes\n",
        "optimizer = Optimizer(net)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VoW9EgXyIKrs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Model training"
      ]
    },
    {
      "metadata": {
        "id": "FhRGqWYAFPHh",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Hyperparameters\n",
        "\n",
        "Batch_size = 100 #@param {type:\"number\"}\n",
        "learning_rate = 0.5 #@param {type:\"slider\", min:0, max:1, step:0.1}\n",
        "Epochs_num = 10 #@param {type:\"number\"}\n",
        "lambda_ = 5 #@param {type:\"slider\", min:0, max:10, step:0.1}\n",
        "Regularizer = \"L2\" #@param [\"L1\", \"L2\"]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C_nAuDeirq4e",
        "colab_type": "code",
        "outputId": "ed86ddf8-2b42-4335-c831-12ee0878bae0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "cell_type": "code",
      "source": [
        "train(net, optimizer, np.asarray(train_images), one_hot(train_labels),Batch_size,learning_rate,Epochs_num, np.asarray(test_images), np.asarray(test_labels), regular=[Regularizer,lambda_])\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 : Accuracy => 9517 / 10000\n",
            "Epoch 1 : Accuracy => 9645 / 10000\n",
            "Epoch 2 : Accuracy => 9689 / 10000\n",
            "Epoch 3 : Accuracy => 9721 / 10000\n",
            "Epoch 4 : Accuracy => 9744 / 10000\n",
            "Epoch 5 : Accuracy => 9748 / 10000\n",
            "Epoch 6 : Accuracy => 9767 / 10000\n",
            "Epoch 7 : Accuracy => 9779 / 10000\n",
            "Epoch 8 : Accuracy => 9760 / 10000\n",
            "Epoch 9 : Accuracy => 9764 / 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kq_phzAVJK1P",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Testing the model"
      ]
    },
    {
      "metadata": {
        "id": "WGTPVhW5KR7K",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We choose randomly some images in the test dataset and test them"
      ]
    },
    {
      "metadata": {
        "id": "e_U-GlCFJHuy",
        "colab_type": "code",
        "outputId": "55315f54-ec02-4a14-9793-996f08eb3c44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        }
      },
      "cell_type": "code",
      "source": [
        "rand = randint(0,9999)\n",
        "im=test_images[rand]\n",
        "im = np.reshape(im, ( 28,28))\n",
        "plt.imshow(im)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fa487d99d68>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFKCAYAAACU6307AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "4EbQQx2JvVfg",
        "colab_type": "code",
        "outputId": "22d2033e-62b7-46c9-a29c-ef1a45e248e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "cell_type": "code",
      "source": [
        "im = np.reshape(im, (784))\n",
        "print(\"The decoded number\")\n",
        "print(decode_output(net.test(im)))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The decoded number\n",
            "7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "u56zvEUHPo6K",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}